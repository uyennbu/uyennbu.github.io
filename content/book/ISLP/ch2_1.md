---
title: "Chapter 2: Introduction to Statistical Learning (1)"
date: 2026-01-16
draft: false
series: ["ISLP"]
tags: ["statistics", "machine learning"]
---
Bài viết nằm trong series ISLP, là series mình tóm tắt lại những gì mình đọc trong cuốn "An Introduction to Statistical Learning with applications in Python".
- Trang web của quyển sách: [statlearning.com](https://www.statlearning.com/)
- Trang resources để tải file sách pdf, tải code và data:  [resources](https://www.statlearning.com/resources-python)
- Bài giảng của tác giả được cung cấp bởi đại học Stanford: [Statistical Learning with Python](https://youtube.com/playlist?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ&si=wvVcrbaPvFn4x9wb)

## 2.1 Statistical learning là gì?
Ta bắt đầu bằng một bài toán:

Giả sử chúng ta cần tìm hiểu mối liên kết giữa việc quảng cáo (advertising) và doanh số (sales) của một sản phẩm nào đó. Bộ dữ liệu `Advertising` bao gồm `sales` của sản phẩm đó trên 200 thị trường khác nhau, cùng với chi phí quảng cáo (advertising budgets) cho sản phẩm trong từng thị trường này cho 3 phương tiện truyền thông: `TV`, `radio` và `newspaper`. Nếu chúng ta tìm ra được mối quan hệ giữa chi phí quảng cáo cho từng phương tiện và doanh số chúng ta có thể điều chỉnh chi phí cho phù hợp để đạt được doanh thu cao hơn.

- Trong trường hợp này chi phí quảng cáo là *input variables*, được kí hiệu là $X$: $X_1, X_2, X_3$ lần lượt là chi phí quảng cáo bằng `TV`, `radio` và `newspaper`. *input* còn được gọi với các tên khác như *predictors*, *independent variables* (biến độc lập), *features* (đặc trưng) hoặc chỉ đơn giản là *variables* (biến)
- `sales` là một *output variable*, hay còn được gọi là *response* hoặc *dependent variable* (biến phụ thuộc), được kí hiệu là $Y$

Giả sử chúng ta quan sát được (thu được) dữ liệu $Y$ và $p$ biến khác nhau: $X_1, X_2, ..., X_p$. Ta giả sử rằng có một mối quan hệ nào đó giữa $Y$ và $X = (X_1, X_2, ..., X_p)$. Mối quan hệ này có thể viết khái quát bằng dạng:
$$Y = f(X) + \epsilon$$
Ở đây, $f$ là một hàm cố định nhưng chưa biết của $X_1, ..., X_p$ và $\epsilon$ là lỗi ngẫu nhiên (*random error term*). $\epsilon$ không phụ thuộc và $X$ và có kỳ vọng bằng 0. Hàm $f$ thể hiện thông tin có hệ thống mà $X$ cung cấp về $Y$.

Tóm lại, statistical learning nói đến một tập các cách tiếp cận để ước lượng hàm $f$.

### 2.1.1 Mục đích của việc ước lượng $f$
Có hai mục đích chính cho việc ước lượng làm $f$: dự đoán (prediction) và suy luận (inference).
#### Dự đoán (prediction)
Ta ước lượng hàm $f$ để dự đoán giá trị của $Y$ khi biết giá trị của $X$:
$$\hat Y = \hat f(X)$$
ở đây $\hat f$ và $\hat Y$ lần lượt là các giá trị ước lượng của $f$ và $Y$.

Trong trường hợp này, ta chỉ quan tâm đến độ chính xác của giá trị ước lượng cho $Y$ mà không quan tâm đến hàm $f$ thật sự là gì, vì thế hàm $f$ thường được coi là một *black box*.

**Error:**
Độ chính xác của $\hat Y$ như là một dự đoán cho $Y$ phụ thuộc vào hai yếu tố: *reducible error* (lỗi có thể giảm được) và *irreducible error* (lỗi không thể giảm được). 
- *reducible error*: Nhìn chung $\hat f$ không phải là ước lượng hoàn hảo cho $f$, tạo ra *reducible error*. Lỗi này giảm được vì ta có khả năng tìm được một hàm khác tốt hơn.
- *irreduciable error*: Dù cho ta có tìm được chính xác hàm $f$ thì ta không thể dự đoán chính xác $Y$ do $Y$ cũng là một hàm phụ thuộc vào $\epsilon$, một đại lượng không phụ thuộc vào $X$ ($Y = f(X) + \epsilon$). Đại lượng $\epsilon$ đại diện cho những biến khác mà có thể cũng hữu ích nhưng ta không đo lường nó và không đưa nó vào hàm $f$ (unmeasured variables) hoặc những ngẫu nhiên khác (unmeasured variation).
$$
\begin{split}
  E(Y - \hat Y)^2 & = E[f(X) + \epsilon - \hat f(X)] \\
                  & = [f(X) - \hat f(X)]^2 + Var(\epsilon)\\
                  &\quad \text(Reducible) \quad \quad(Irreducible)
\end{split}
$$
trong đó, $E(Y - \hat Y)^2$ là giá trị trung bình hay kì vọng (*expected value*) của bình phương chênh lệch giữa giá trị dự đoán và giá trị thực của $Y$ và Var($\epsilon$) là phương sai (*variance*) ứng với error term $\epsilon$

#### Suy luận (inference)
Ta muốn hiểu về mối liên hết giữa $Y$ và $X$. Trong trường hợp này, mục tiêu của ta không phải là dự đoán chính xác $Y$ mà là tìm ra dạng giống nhất đối với $f$. Khi này, ta không thể coi $\hat f$ là một black box được nữa.

Trong trường hợp này, ta có thể muốn trả lời một số câu hỏi:
- Biến nào có ảnh hưởng lớn nhất đến output?
- Mối quan hệ giữa output và từng biến đầu vào là gì?
- Mối quan hệ giữa output và input là tuyến tính hay là một mối quan hệ phức tạp hơn?

### 2.1.2 Làm thế nào để ước lượng $f$?
Khái niệm:
- *model* (mô hình): là hàm số $f$ hay $\hat f$
- *training data* (dữ liệu huấn luyện): tập dữ liệu ta thu được, dùng để ước lượng hàm $f$

Kí hiệu:
- $n$: số điểm dữ liệu thu được (số observations)
- $p$: số biến
- $x_{ij}$ là giá trị của biến thứ $j$ của điểm thứ $i$ (observation $i$) ($i = 1, 2, 3, ..., n$ và $j = 1, 2, ..., p$)
- $y_i$ phản hồi của observation $i$
Dữ liệu huấn luyện có thể biểu diễn dưới dạng $\{(x_1, y_1), ..., (x_n, y_n)\}$ trong đó $x_i = (x_{i1}, x_{i2}, ..., x_{ip})^T$

Có hai cách chính để ước lượng f: tham số (*parametric methods*) và phi tham số (*non-paramatric methods*)
#### Parametric methods
Là cách tiếp cận dựa trên mô hình (hàm), bao gồm 2 bước
1. Đưa ra giả định về dạng của hàm $f$. Ví dụ ta có thể giả định rằng $f$ là tuyến tính:
$$f(X) = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p$$
2. Dùng training data để *fit* hoặc *train model*, tức là ước lượng các tham số $\beta_0, ..., \beta_p$ sao cho:
$$Y \approx \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_pX_p$$

Các tiếp cận này đơn giản hóa việc ước lượng hàm $f$ bằng cách đưa nó về ước lượng các tham số. Tuy nhiên, nhược điểm là mô hình được chọn ban đầu có thể rất khác với hàm $f$ thực tế. Để tránh điều này ta có thể dùng các mô hình phức tạp (*flexible models*), giúp fit nhiều dạng hàm có thể xảy ra hơn. Nhưng mô hình phức tạp hơn thì có nguy cơ xảy ra *overfitting* cao hơn (*overfitting* xảy ra khi mô hình học theo cả lỗi hay *noise* trong dữ liệu)

#### Non-parametric methods
Các phương pháp phi tham số không đặt giả định rõ ràng về dạng của $f$, mà tìm một ước lượng mà gần với các điểm dữ liệu nhất có thể mà không quá gồ ghề (*rough*)
<!--ví dụ: thin-plate spline-->
### 2.1.3 Sự đánh đổi giữa độ chính xác và khả năng giải thích của mô hình
Mô hình càng phức tạp (càng *flexible*) thì khả năng giải thích càng kém (hãy nghĩ đến black box)

![A representation of the tradeoff between flexibility and interpretability](https://www.stat.cmu.edu/~pfreeman/flexibility.png)
### 2.1.4 Có giám sát vs không giám sát
Phần lớn các vấn đề có thể chia làm 2 loại: học có giám sát (*supervised learning*) và học không giám sát (*unsupervised learning*)
- Học có giám sát: Với mỗi predictor $x_i$ có phản hồi $y_i$ tương ứng, ta muốn huấn luyện mô hình để đưa ra đúng dự đoán về $y$ dựa trên $x$ hoặc hiểu rõ hơn mối quan hệ giữa $x$ và $y$
    + Chia thành bài toán hồi quy (*regression*) hoặc bài toán phân loại (*classification*)
- Học không giám sát: $x_i$ không có giá trị $y_i$ tương ứng, ta muốn tìm hiểu về mối quan hệ giữa các giá trị hay các observations với nhau.
    + Tiêu biểu như bài toán phân cụm (*clustering*)
- Học bán giám sát (*semi-supervised learning*): khi một phần dữ liệu có nhãn, một phần khác thì không.

### 2.1.5 Hồi quy vs phân loại
Các giá trị có thể là định lượng (*quantitative*) (các giá trị số như tuổi, chiều cao, ...) hoặc định tính (*quanlitative*, hay *categorical*) (các giá trị phân loại như tình trạng hôn nhân, nhóm máu, ...)

**Hồi quy** (*regression*): output $y$ là giá trị định lượng

**Phân loại** (*classification*): output $y$ là giá trị định tính

---
Bài viết của mình có thể còn nhiều thiếu sót, mình rất vui nếu được nhận góp ý từ bạn đọc để bài viết hoàn thiện và trở nên tốt hơn. Chúc bạn một ngày tốt lành ☘️

Email của mình : uyennguyen.nbu@gmail.com