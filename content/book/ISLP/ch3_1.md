---
title: "Chapter 3: Linear Regression (1)"
date: 2026-01-23
draft: true
series: ["ISLP"]
tags: ["statistics", "machine learning"]
---
Bài viết nằm trong series ISLP, là series mình tóm tắt lại những gì mình đọc trong cuốn "An Introduction to Statistical Learning with applications in Python".
- Trang web của quyển sách: [statlearning.com](https://www.statlearning.com/)
- Trang resources để tải file sách pdf, tải code và data:  [resources](https://www.statlearning.com/resources-python)
- Bài giảng của tác giả được cung cấp bởi đại học Stanford: [Statistical Learning with Python](https://youtube.com/playlist?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ&si=wvVcrbaPvFn4x9wb)

## 3.0 Giới thiệu về bài toán hồi quy tuyến tính
Hồi quy tuyến tính (*linear regression*) là một cách tiếp cận rất đơn giản trong học có giám sát (*supervised learning*). Mặc dù rất đơn giản nhưng hồi quy tuyến tính lại rất hữu dụng, nhiều mô hình phức tạp trong thống kê thực chất có thể xem như sự khái quát hóa hoặc mở rộng của mô hình này.

Trở lại với ví dụ về `Advertising` trong chương 2: coi `sales` như một hàm phụ thuộc vào kinh phí quảng cáo trên `TV`, `radio` và báo. Để đề ra chiến lược kinh doanh phù hợp, ta có thể cần trà lời một số câu hỏi:
- Liệu có mối quan hệ nào giữa chi phí quảng cáo và sales không?
- Nếu có thì môi quan hệ trên có mạnh không?
- Phương tiện quảng cáo nào tác động đến doanh số? Một vài hay tất cả?
- Sự tác động của từng phương tiện quảng cáo đến doanh số như thế nào?
- Ta có thể dự đoán chính xác đến đâu doanh số tương lai?
- Mối quan hệ có tuyến tính không?
- Có mối liên hệ/ tương tác nào giữa các phương tiện quảng cáo không?

Mô hình hồi quy tuyến tính sẽ giúp ta trả lời các câu hỏi trên.

## 3.1 Hồi quy tuyến tính đơn giản (*Simple linear regression*)
Hồi quy tuyến tính giả sử rằng có mối quan hệ tuyến tính giữa $X$ và $Y$, nói cách khác, mối quan hệ giữa $X$ và $Y$ có thể viết được dưới dạng:
$$
    Y \approx \beta_0 + \beta_1X
$$
Ta nói rằng ta đang hồi quy của Y theo X (*regressing Y on X/ Y onto X*). $\beta_0$ là hệ số chặn (*intercept*), $\beta_1$ là hệ số góc (*slope*) của đường hồi quy tuyến tính.

Sau khi sử dụng dữ liệu huấn luyện để tìm $\beta_0, \beta_1$ ta được:
$$
    \hat y = \hat{\beta}_0 + \hat{\beta_1}x
$$
Kí hiệu $\hat{}$ thể hiện giá trị ước lượng.

### 3.1.1 Ước lượng các hệ số
Ta muốn tìm các hệ số $\beta_0, \beta_1$ sao cho đường thẳng tương ứng gần với các điểm dữ liệu đã biết nhất có thể: $y \approx \hat{y} = \hat{\beta}_0 + \hat{\beta_1}x$.

Có rất nhiều cách để đo sự "gần", trong đó phổ biến nhất là phương pháp bình phương tối thiểu *least square*.

***Residual sum of square***

Với $\hat{y}_i = \beta_0 + \beta_1x_i$ là dự đoán về $Y$ dựa trên giá trị thứ $i$ của $X$. Khi đó $e_i = y_i - \hat{y}_i$ là phần dư (*residual*) thứ $i$ - phần chênh lệch giữa giá quan sát và giá trị dự đoán cho $Y$ của điểm thứ i. Đại lượng tổng phần dư bình phương (*residual sum of squares*) (RSS) được định nghĩa:
$$
    \text{RSS} = e_1^2 + e_2^2 + ... + e_n^2
$$
Bình phương tối thiểu chọn $\beta_0$ và $\beta_1$ để tối thiểu hóa RSS. Bằng các biến đổi trong giải tích, ta thu được:
$$
    \hat{\beta_1} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n}(x_i - \bar{x})^2}\\
    
    \hat{\beta_0} = \bar{y} - \hat{\beta_1}\bar{x}
$$
Trong đó $\bar{y} = \frac{1}{n}\sum_{i=1}{n}y_i$ và $\bar{x} = \frac{1}{n}\sum_{i=1}{n}x_i$ là trung bình mẫu.

### 3.1.2. Đánh giá độ chính xác của các hệ số đã ước lượng


---
Bài viết của mình có thể còn nhiều thiếu sót, mình rất vui nếu được nhận góp ý từ bạn đọc để bài viết hoàn thiện và trở nên tốt hơn. Chúc bạn một ngày tốt lành ☘️

Email của mình : uyennguyen.nbu@gmail.com