<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn | Uyen&#39;s blog</title>
<meta name="keywords" content="statistics, machine learning">
<meta name="description" content="Bài viết nằm trong series ISLP, là series mình tóm tắt lại những gì mình đọc trong cuốn &quot;An Introduction to Statistical Learning with applications in Python&quot;.

Trang web của quyển sách: statlearning.com
Trang resources để tải file sách pdf, tải code và data:  resources
Bài giảng của tác giả được cung cấp bởi đại học Stanford: Statistical Learning with Python


Từ chương 3 này trở đi, ở đầu mỗi chương mình sẽ đặt ra một số câu hỏi quan trọng để ta cùng ngẫm nghĩ nhé. Các câu hỏi này sẽ được trả lời ở cuối chương.">
<meta name="author" content="">
<link rel="canonical" href="https://uyennbu.github.io/book/islp/ch3_1/">
<link crossorigin="anonymous" href="https://uyennbu.github.io/assets/css/stylesheet.da3211e5ef867bf2b75fd5a6515cfed7195c011e8ab735694e203810a827097b.css" integrity="sha256-2jIR5e&#43;Ge/K3X9WmUVz&#43;1xlcAR6KtzVpTiA4EKgnCXs=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://uyennbu.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://uyennbu.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://uyennbu.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://uyennbu.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://uyennbu.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://uyennbu.github.io/book/islp/ch3_1/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>

<script>
  MathJax = {
    tex: {
      displayMath: [['\[', '\]'], ['$$', '$$']],  
      inlineMath: [['$', '$']]                  
    },
    loader:{
      load: ['ui/safe']
    },
  };
</script>
<meta property="og:url" content="https://uyennbu.github.io/book/islp/ch3_1/">
  <meta property="og:site_name" content="Uyen&#39;s blog">
  <meta property="og:title" content="Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn">
  <meta property="og:description" content="Bài viết nằm trong series ISLP, là series mình tóm tắt lại những gì mình đọc trong cuốn &#34;An Introduction to Statistical Learning with applications in Python&#34;.
Trang web của quyển sách: statlearning.com Trang resources để tải file sách pdf, tải code và data: resources Bài giảng của tác giả được cung cấp bởi đại học Stanford: Statistical Learning with Python Từ chương 3 này trở đi, ở đầu mỗi chương mình sẽ đặt ra một số câu hỏi quan trọng để ta cùng ngẫm nghĩ nhé. Các câu hỏi này sẽ được trả lời ở cuối chương.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="book">
    <meta property="article:published_time" content="2026-02-12T00:00:00+00:00">
    <meta property="article:modified_time" content="2026-02-12T00:00:00+00:00">
    <meta property="article:tag" content="Statistics">
    <meta property="article:tag" content="Machine Learning">
    <meta property="og:image" content="https://uyennbu.github.io/img/coverImg/lovely1.jpg">
      <meta property="og:see_also" content="https://uyennbu.github.io/book/islp/ch2_2/">
      <meta property="og:see_also" content="https://uyennbu.github.io/book/islp/ch2_1/">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://uyennbu.github.io/img/coverImg/lovely1.jpg">
<meta name="twitter:title" content="Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn">
<meta name="twitter:description" content="Bài viết nằm trong series ISLP, là series mình tóm tắt lại những gì mình đọc trong cuốn &quot;An Introduction to Statistical Learning with applications in Python&quot;.

Trang web của quyển sách: statlearning.com
Trang resources để tải file sách pdf, tải code và data:  resources
Bài giảng của tác giả được cung cấp bởi đại học Stanford: Statistical Learning with Python


Từ chương 3 này trở đi, ở đầu mỗi chương mình sẽ đặt ra một số câu hỏi quan trọng để ta cùng ngẫm nghĩ nhé. Các câu hỏi này sẽ được trả lời ở cuối chương.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Books",
      "item": "https://uyennbu.github.io/book/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn",
      "item": "https://uyennbu.github.io/book/islp/ch3_1/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn",
  "name": "Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn",
  "description": "Bài viết nằm trong series ISLP, là series mình tóm tắt lại những gì mình đọc trong cuốn \u0026quot;An Introduction to Statistical Learning with applications in Python\u0026quot;.\nTrang web của quyển sách: statlearning.com Trang resources để tải file sách pdf, tải code và data: resources Bài giảng của tác giả được cung cấp bởi đại học Stanford: Statistical Learning with Python Từ chương 3 này trở đi, ở đầu mỗi chương mình sẽ đặt ra một số câu hỏi quan trọng để ta cùng ngẫm nghĩ nhé. Các câu hỏi này sẽ được trả lời ở cuối chương.\n",
  "keywords": [
    "statistics", "machine learning"
  ],
  "articleBody": "Bài viết nằm trong series ISLP, là series mình tóm tắt lại những gì mình đọc trong cuốn \"An Introduction to Statistical Learning with applications in Python\".\nTrang web của quyển sách: statlearning.com Trang resources để tải file sách pdf, tải code và data: resources Bài giảng của tác giả được cung cấp bởi đại học Stanford: Statistical Learning with Python Từ chương 3 này trở đi, ở đầu mỗi chương mình sẽ đặt ra một số câu hỏi quan trọng để ta cùng ngẫm nghĩ nhé. Các câu hỏi này sẽ được trả lời ở cuối chương.\nHồi quy tuyến tính là gì? Khi nào thì dùng hồi quy tuyến tính? Hồi quy tuyến tính giúp ta trả lời những câu hỏi gì? Các tham số trong mô hình hồi quy tuyến tính được tìm bằng cách nào? Đánh giá độ chính xác ra sao (độ chính xác của tham số, độ chính xác của mô hình)? Những biến thể của hồi quy tuyến tính (đó là những biến thể nào? giúp giải quyết vấn đề gì) 3.1 Hồi quy tuyến tính đơn (Simple linear regression) Hồi quy tuyến tính giả sử rằng có mối quan hệ tuyến tính giữa $X$ và $Y$, nói cách khác, mối quan hệ giữa $X$ và $Y$ có thể viết được dưới dạng: $$ Y \\approx \\beta_0 + \\beta_1X $$ Ta nói rằng ta đang hồi quy của Y theo X (regressing Y on X/ Y onto X). $\\beta_0$ là hệ số chặn (intercept), $\\beta_1$ là hệ số góc (slope) của đường hồi quy tuyến tính.\nSau khi sử dụng dữ liệu huấn luyện để tìm $\\beta_0, \\beta_1$ ta được: $$ \\hat y = \\hat{\\beta}_0 + \\hat{\\beta_1}x $$ Kí hiệu $\\hat{}$ thể hiện giá trị ước lượng.\n3.1.1 Ước lượng các hệ số Ta muốn tìm các hệ số $\\beta_0, \\beta_1$ sao cho đường thẳng tương ứng gần với các điểm dữ liệu đã biết nhất có thể: $y \\approx \\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta_1}x$.\nCó rất nhiều cách để đo sự “gần”, trong đó phổ biến nhất là phương pháp bình phương tối thiểu least square.\nResidual sum of square\nVới $\\hat{y}_i = \\beta_0 + \\beta_1x_i$ là dự đoán về $Y$ dựa trên giá trị thứ $i$ của $X$. Khi đó $e_i = y_i - \\hat{y}_i$ là phần dư (residual) thứ $i$ - phần chênh lệch giữa giá quan sát và giá trị dự đoán cho $Y$ của điểm thứ i. Đại lượng tổng phần dư bình phương (residual sum of squares) (RSS) được định nghĩa: $$ \\text{RSS} = e_1^2 + e_2^2 + ... + e_n^2 $$ Bình phương tối thiểu chọn $\\beta_0$ và $\\beta_1$ để tối thiểu hóa RSS. Bằng các biến đổi trong giải tích, ta thu được: $$ \\hat{\\beta_1} = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\\\\ \\hat{\\beta_0} = \\bar{y} - \\hat{\\beta_1}\\bar{x} $$ Trong đó $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n}y_i$ và $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}x_i$ là trung bình mẫu.\nĐường bình phương tối thiểu cho ví dụ về chi phí quảng cáo: 3.1.2. Đánh giá độ chính xác của các hệ số đã ước lượng Ở mục này có hai ý chính ta cần quan tâm:\nSai số chuẩn của ước lượng và khoảng tin cậy Liệu X có thật sự có tác động lên Y hay mô hình hồi quy tuyến tính có thật sự ý nghĩa không. Vấn đề 1. Khoảng tin cậy cho hệ số của mô hình\nNếu như mối quan hệ giữa X và Y thực sự có thể biểu diễn xấp xỉ bằng đường thẳng, thì đường thẳng này được gọi là đường hồi quy tổng thể (population regression line), là đường thẳng tốt nhất có thể dùng để biểu diễn quan hệ giữa X và Y: $$ Y = \\beta_0 + \\beta_1 X + \\epsilon $$ Trong đó, hệ số chặn $\\beta_0$ là kỳ vọng của Y khi X = 0, $\\beta_1$ cho biết lượng tăng trung bình của Y khi X tăng 1 đơn vị và $\\epsilon$ là sai số (đến từ việc mối quan hệ thực sự có thể không phải là tuyến tính và cũng đến từ những tác động bên ngoài khác đến Y). Ta thường giả định rằng $\\epsilon$ độc lập với X.\nĐường thẳng với hệ số nhận được từ phương pháp bình phương tối thiểu như phần trên được gọi là đường bình phương tối thiểu (least square line).\nĐường hồi quy tổng thể là quy nhất, trong khi đường least squares thì lại có rất nhiều do được tính toán từ mẫu. Mẫu khác nhau sẽ có những đường least squares khác nhau. Trong hình dưới đây, đường màu đỏ là đường hồi quy tổng thể, màu xanh đậm là đường least squares ta tính được ở trên còn các đường xanh nhạt là các đường least squares ứng với các bộ dữ liệu khác. Có thể thấy luôn có sự khác nhau giữa các đường least squares và đường hồi quy tổng thể. Tuy nhiên least squares là ước lượng không chệch, nghĩa là nếu ta lấy trung bình các ước lượng cho $\\hat{\\beta_0}$ và $\\hat{\\beta_1}$ trên một lượng lớn các tập dữ liệu khác nhau thì giá trị $\\hat{\\beta_0}, \\hat{\\beta_1}$ này sẽ rất gần với giá trị của $\\beta_0$ và $\\beta_1$. Ta có thể thấy điều này trong hình bên phải.\nSai số chuẩn (standard error) cho biết ước lượng $\\hat{\\beta_0}$ và $\\hat{\\beta_1}$ sai khác như thế nào so với giá trị thực của $\\beta_0$ và $\\beta_1$. Với least squares sai số chuẩn được tính theo công thức: $$ SE(\\hat{\\beta_0})^2 = \\sigma^2[\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}], \\quad SE(\\hat{\\beta_1})^2 = \\frac{\\sigma^2}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2} $$ Trong đó $\\sigma^2 = Var(\\epsilon)$. Khi sử dụng công thức này ta đã giả định rằng $\\epsilon$ có cùng phương sai và không tương quan với nhau. Điều này không đúng (có thể xem ở hình trước) tuy nhiên đây vẫn là một cách xấp xỉ tốt.\nTheo công thức này, $SE(\\hat{\\beta_1})$ càng nhỏ khi $x_i$ càng phân tán (dữ liệu leverage), để dễ hình dung ta có thể nghĩ đến việc tìm hệ số góc cho đường thẳng hồi quy khi dữ liệu tụ lại thành một đám tròn, so với khi dữ liệu tản dẹt ra.\nVới công thức tính $SE(\\hat{\\beta_0})$ thì nếu $\\bar{x} = 0$, $SE(\\hat{\\beta_1}) = \\sigma^2/n = SE(\\hat{\\mu})$ là phương sai của ước lượng cho kì vọng của Y dựa trên trung bình mẫu. Chú ý rằng $\\beta_0$ là kỳ vọng của $Y$ khi X = 0.\nTrên thực tế, ta không biết $\\sigma^2$ nhưng ta có thể ước lượng cho $\\sigma$ bằng RSE (residual standard error, sai số chuẩn phần dư) dựa trên dữ liệu theo công thức $RSE = \\sqrt{RSS/(n-2)}$.\nSai số chuẩn có thể được dùng để tính khoảng tin cậy confident interval. Khoảng tin cậy 95% là khoảng mà có xác suất 95% rằng giá trị thực sẽ nằm trong nó. Trong hồi quy tuyến tính, khoảng tin cậy 95% cho $\\beta_1$ được xấp xỉ bởi: $$ \\hat{\\beta_1} \\pm 2 \\cdot SE(\\hat{\\beta_1}) \\\\ \\text{hay } [\\hat{\\beta_1} - 2 \\cdot SE(\\hat{\\beta_1}), \\hat{\\beta_1} + 2 \\cdot SE(\\hat{\\beta_1})] $$ Tương tự với $\\beta_0$.\nTrong bài toán về sales và chi phí quảng cáo trên, khoảng tin cậy 95% cho $\\beta_0$ và $\\beta_1$ lần lượt là [6.130, 7.935] và [0.042, 0.053]. Điều này có nghĩa là nếu không có quảng cáo thì trung bình lượng sales sẽ là 6,130 đến 7,935 sản phẩm. Thêm vào đó, với mỗi 1000 đô chi thêm cho quảng cáo trên TV thì doanh số tăng 42 đến 53 đơn vị sản phẩm.\nVấn đề 2: Kiểm định về hệ số của mô hình\nMột câu hỏi ta cần quan tâm là, liệu X có thật sự có tác động lên Y hay không? Hay liệu có thật sự có mối quan hệ nào giữa X và Y hay không. Vì nếu không thì mô hình có hệ số góc = 0, hay $Y = \\beta_0 + \\epsilon$, X không có ảnh hưởng gì đến Y.\nTa cần kiểm định giả thiết (null hypothesis):\n$H_0$: không có mối quan hệ giữa X và Y hay $\\beta_1 = 0$ với đối thiết (alternative hypothesis): $H_a$: có mỗi quan hệ nào đó giữa X và Y, hay $\\beta_1 \\neq 0$ Ta sẽ bác bỏ $H_0$ nếu hệ số đủ xa so vơi 0. Ta kiểm tra điều này bằng cách so khoảng cách giữa $\\beta_1$ và 0 với SE($\\hat{\\beta_1}$). Nếu sai số của ước lượng là nhỏ, thì giá trị của $\\hat{\\beta_1}$ dù rất nhỏ nhưng cũng đáng kể. Ngược lại, nếu sai số ước lượng là lớn thì $\\hat{\\beta_1}$ cũng phải lớn tương ứng.\nTa sử dụng test thống kê T, giúp đo xem $\\hat{\\beta_1}$ cách 0 bao nhiêu độ lệch chuẩn.: $$ t = \\frac{\\hat{\\beta_1} - 0}{SE(\\hat{\\beta_1})} $$ Nếu $H_0$ đúng, nghĩa là không có mối quan hệ giữa X và Y thì đại lượng t tuân theo phân phối t-student với $n-2$ bậc tự do, phân phối này xâp xỉ phân phối chuẩn tắc nếu n \u003e 30.\nĐại lượng p-value là xác suất để thu được giá trị t như ta đã tính được ở trên nếu $H_0$ đúng. Nghĩa là, để kiểm định xem $H_0$ có đúng không, ta giả sử rằng nó đúng, khi đó ta sẽ xấp xỉ được phân phối của t và từ đó tính xác suất nhận được giá trị t như ta đã tính. Nếu xác suất này đủ nhỏ, ta sẽ bác bỏ $H_0$ và ngược lại.\nVậy ta sẽ bác bỏ $H_0$, hay ta nói rằng X và Y có mối quan hệ nào đó nếu p-value đủ nhỏ (thường là nhỏ hơn 0.05, ứng với độ tin cậy 95%).\n3.1.3. Đánh giá độ chính xác của mô hình Sau khi đã bác bỏ $H_0$, điều tiếp theo ta muốn làm đó là đánh giá múc độ phù hợp với dữ liệu của mô hình. Ta có một số hệ số để đánh giá như sau:\nResidual Standard Error\nKể cả khi ta biết được đường hồi quy thật sự thì dự đoán của mô hình vẫn luôn có sai số $\\epsilon$ do nhiều tác động khác bên ngoài.\nRSE là ước lượng cho sai số chuẩn của $\\epsilon$, hay nó là lượng chênh lệch trung bình của Y so với đường hồi quy thực sự (true regression line): $$ RSE = \\sqrt{\\frac{1}{n - 2}RSS} = \\sqrt{\\frac{1}{n-2}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2} $$RSE còn có thể coi như đại lượng đo lường độ thiếu phù hợp của mô hình lack of fit so với dữ liệu.\nThông thường, RSE càng lớn tức là mô hình không thật sự phù hợp tốt với dữ liệu.\n$R^2$ statistic\nRSE cho đo lường độ lệch tuyệt đối do đó độ lớn của nó còn phụ thuộc vào đơn vị của Y, làm việc so sánh giữa các mô hình gặp khó khăn hơn.\n$R^2$ là một cách khác để đo độ phù hợp, do được tính theo tỉ lệ nên nó không phụ thuộc vào đơn vị của Y và luôn có giá trị trong khoảng (0,1), được xác định bởi: $$ R^2 = \\frac{TSS - RSS}{TSS} = 1 - \\frac{RSS}{TSS} $$ Trong đó TSS = $\\sum_{i=1}^{n}(y_i - \\bar{y})^2$ là tổng bình phương trung bình total sum of squares, đo lường tổng phương sai của phản hồi Y, hay sự biến động của Y trước khi sử dụng hồi quy. Ngược lại, RSS đo lường độ biến động mà không giải thích được sau khi áp dụng hồi quy.\nDo đó, $R^2$ đo lường tỉ lệ độ biến động variability trong Y mà có thể giải thích được bằng X.\n$R^2$ gần với 1 nghĩa là có một tỉ lệ lớn của sự biến động được giải thích bởi hồi quy. Còn $R^2$ gần với 0 nghĩa là hồi quy không thể giải thích được nhiều sự biến động trong phản hồi Y, điều này có thể do mô hình tuyến tính là sai hoặc phương sai của sai số $\\sigma^2$ là cao, hoặc cả hai.\n$R^2$ vs correlation\nHệ số tương quan correlation: r = Cor(X,Y) cũng giúp đo lường mối quan hệ tuyến tính giữa X và Y, được tính bởi: $$ Cor(X,Y) = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^{n}(y_i-\\bar{y})^2}} $$ Trong hồi quy tuyến tính đơn ta có thể dùng r thay cho $R^2$, và ta cũng chứng minh được rằng $R^2 = r^2$. Tuy nhiên với hồi quy tuyến tính đa biến, ta không dùng r mà dùng $R^2$ do r chỉ dựa trên cặp 2 biến chứ không phải giữa một lượng lớn các biến.\nBài viết được viết theo ý hiểu của mình nên có thể còn nhiều thiếu sót, mình rất vui nếu được nhận góp ý từ bạn đọc để bài viết hoàn thiện và trở nên tốt hơn. Chúc bạn một ngày tốt lành ☘️\nEmail của mình : uyennguyen.nbu@gmail.com\n",
  "wordCount" : "2151",
  "inLanguage": "en",
  "image":"https://uyennbu.github.io/img/coverImg/lovely1.jpg","datePublished": "2026-02-12T00:00:00Z",
  "dateModified": "2026-02-12T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://uyennbu.github.io/book/islp/ch3_1/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Uyen's blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://uyennbu.github.io/favicon.ico"
    }
  }
}
</script>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://uyennbu.github.io/" accesskey="h" title="Uyen&#39;s blog (Alt + H)">Uyen&#39;s blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://uyennbu.github.io/series/" title="Series">
                    <span>Series</span>
                </a>
            </li>
            <li>
                <a href="https://uyennbu.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://uyennbu.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="https://uyennbu.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://uyennbu.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://uyennbu.github.io/book/">Books</a></div>
    <h1 class="post-title entry-hint-parent">
      Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn
    </h1>
    <div class="post-meta"><span title='2026-02-12 00:00:00 +0000 UTC'>February 12, 2026</span>&nbsp;·&nbsp;<span>11 min</span>

</div>
  </header> 
<figure class="entry-cover">
        <img loading="eager" src="https://uyennbu.github.io/img/coverImg/lovely1.jpg" alt="An image of lovely flowers">
        
</figure><div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#31-h%e1%bb%93i-quy-tuy%e1%ba%bfn-t%c3%adnh-%c4%91%c6%a1n-simple-linear-regression" aria-label="3.1 Hồi quy tuyến tính đơn (Simple linear regression)">3.1 Hồi quy tuyến tính đơn (Simple linear regression)</a><ul>
                        
                <li>
                    <a href="#311-%c6%b0%e1%bb%9bc-l%c6%b0%e1%bb%a3ng-c%c3%a1c-h%e1%bb%87-s%e1%bb%91" aria-label="3.1.1 Ước lượng các hệ số">3.1.1 Ước lượng các hệ số</a></li>
                <li>
                    <a href="#312-%c4%91%c3%a1nh-gi%c3%a1-%c4%91%e1%bb%99-ch%c3%adnh-x%c3%a1c-c%e1%bb%a7a-c%c3%a1c-h%e1%bb%87-s%e1%bb%91-%c4%91%c3%a3-%c6%b0%e1%bb%9bc-l%c6%b0%e1%bb%a3ng" aria-label="3.1.2. Đánh giá độ chính xác của các hệ số đã ước lượng">3.1.2. Đánh giá độ chính xác của các hệ số đã ước lượng</a></li>
                <li>
                    <a href="#313-%c4%91%c3%a1nh-gi%c3%a1-%c4%91%e1%bb%99-ch%c3%adnh-x%c3%a1c-c%e1%bb%a7a-m%c3%b4-h%c3%acnh" aria-label="3.1.3. Đánh giá độ chính xác của mô hình">3.1.3. Đánh giá độ chính xác của mô hình</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>Bài viết nằm trong series ISLP, là series mình tóm tắt lại những gì mình đọc trong cuốn <code>&quot;An Introduction to Statistical Learning with applications in Python&quot;</code>.</p>
<ul>
<li>Trang web của quyển sách: <a href="https://www.statlearning.com/">statlearning.com</a></li>
<li>Trang resources để tải file sách pdf, tải code và data:  <a href="https://www.statlearning.com/resources-python">resources</a></li>
<li>Bài giảng của tác giả được cung cấp bởi đại học Stanford: <a href="https://youtube.com/playlist?list=PLoROMvodv4rPP6braWoRt5UCXYZ71GZIQ&amp;si=wvVcrbaPvFn4x9wb">Statistical Learning with Python</a></li>
</ul>
<hr>
<p>Từ chương 3 này trở đi, ở đầu mỗi chương mình sẽ đặt ra một số câu hỏi quan trọng để ta cùng ngẫm nghĩ nhé. Các câu hỏi này sẽ được trả lời ở cuối chương.</p>
<ol>
<li>Hồi quy tuyến tính là gì?</li>
<li>Khi nào thì dùng hồi quy tuyến tính? Hồi quy tuyến tính giúp ta trả lời những câu hỏi gì?</li>
<li>Các tham số trong mô hình hồi quy tuyến tính được tìm bằng cách nào? Đánh giá độ chính xác ra sao (độ chính xác của tham số, độ chính xác của mô hình)?</li>
<li>Những biến thể của hồi quy tuyến tính (đó là những biến thể nào? giúp giải quyết vấn đề gì)</li>
</ol>
<h2 id="31-hồi-quy-tuyến-tính-đơn-simple-linear-regression">3.1 Hồi quy tuyến tính đơn (<em>Simple linear regression</em>)<a hidden class="anchor" aria-hidden="true" href="#31-hồi-quy-tuyến-tính-đơn-simple-linear-regression">#</a></h2>
<p>Hồi quy tuyến tính giả sử rằng có mối quan hệ tuyến tính giữa $X$ và $Y$, nói cách khác, mối quan hệ giữa $X$ và $Y$ có thể viết được dưới dạng:
</p>
$$
    Y \approx \beta_0 + \beta_1X
$$<p>
Ta nói rằng ta đang hồi quy của Y theo X (<em>regressing Y on X/ Y onto X</em>). $\beta_0$ là hệ số chặn (<em>intercept</em>), $\beta_1$ là hệ số góc (<em>slope</em>) của đường hồi quy tuyến tính.</p>
<p>Sau khi sử dụng dữ liệu huấn luyện để tìm $\beta_0, \beta_1$ ta được:
</p>
$$
    \hat y = \hat{\beta}_0 + \hat{\beta_1}x
$$<p>
Kí hiệu $\hat{}$ thể hiện giá trị ước lượng.</p>
<h3 id="311-ước-lượng-các-hệ-số">3.1.1 Ước lượng các hệ số<a hidden class="anchor" aria-hidden="true" href="#311-ước-lượng-các-hệ-số">#</a></h3>
<p>Ta muốn tìm các hệ số $\beta_0, \beta_1$ sao cho đường thẳng tương ứng gần với các điểm dữ liệu đã biết nhất có thể: $y \approx \hat{y} = \hat{\beta}_0 + \hat{\beta_1}x$.</p>
<p>Có rất nhiều cách để đo sự &ldquo;gần&rdquo;, trong đó phổ biến nhất là phương pháp bình phương tối thiểu <em>least square</em>.</p>
<p><em><strong>Residual sum of square</strong></em></p>
<p>Với $\hat{y}_i = \beta_0 + \beta_1x_i$ là dự đoán về $Y$ dựa trên giá trị thứ $i$ của $X$. Khi đó $e_i = y_i - \hat{y}_i$ là phần dư (<em>residual</em>) thứ $i$ - phần chênh lệch giữa giá quan sát và giá trị dự đoán cho $Y$ của điểm thứ i. Đại lượng tổng phần dư bình phương (<em>residual sum of squares</em>) (RSS) được định nghĩa:
</p>
$$
    \text{RSS} = e_1^2 + e_2^2 + ... + e_n^2
$$<p>
Bình phương tối thiểu chọn $\beta_0$ và $\beta_1$ để tối thiểu hóa RSS. Bằng các biến đổi trong giải tích, ta thu được:
</p>
$$
    \hat{\beta_1} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n}(x_i - \bar{x})^2}\\
    \hat{\beta_0} = \bar{y} - \hat{\beta_1}\bar{x}
$$<p>
Trong đó $\bar{y} = \frac{1}{n}\sum_{i=1}^{n}y_i$ và $\bar{x} = \frac{1}{n}\sum_{i=1}^{n}x_i$ là trung bình mẫu.</p>
<p>Đường bình phương tối thiểu cho ví dụ về chi phí quảng cáo:
<img alt="ls_line_avtising" loading="lazy" src="https://uyennbu.github.io/img/Chapter3/3_1.jpg"></p>
<h3 id="312-đánh-giá-độ-chính-xác-của-các-hệ-số-đã-ước-lượng">3.1.2. Đánh giá độ chính xác của các hệ số đã ước lượng<a hidden class="anchor" aria-hidden="true" href="#312-đánh-giá-độ-chính-xác-của-các-hệ-số-đã-ước-lượng">#</a></h3>
<p>Ở mục này có hai ý chính ta cần quan tâm:</p>
<ul>
<li>Sai số chuẩn của ước lượng và khoảng tin cậy</li>
<li>Liệu X có thật sự có tác động lên Y hay mô hình hồi quy tuyến tính có thật sự ý nghĩa không.</li>
</ul>
<p><strong>Vấn đề 1. Khoảng tin cậy cho hệ số của mô hình</strong></p>
<p>Nếu như mối quan hệ giữa X và Y thực sự có thể biểu diễn xấp xỉ bằng đường thẳng, thì đường thẳng này được gọi là đường hồi quy tổng thể (<em>population regression line</em>), là đường thẳng tốt nhất có thể dùng để biểu diễn quan hệ giữa X và Y:
</p>
$$
    Y = \beta_0 + \beta_1 X + \epsilon
$$<p>
Trong đó, hệ số chặn $\beta_0$ là kỳ vọng của Y khi X = 0, $\beta_1$ cho biết lượng tăng trung bình của Y khi X tăng 1 đơn vị và $\epsilon$ là sai số (đến từ việc mối quan hệ thực sự có thể không phải là tuyến tính và cũng đến từ những tác động bên ngoài khác đến Y). Ta thường giả định rằng $\epsilon$ độc lập với X.</p>
<p>Đường thẳng với hệ số nhận được từ phương pháp bình phương tối thiểu như phần trên được gọi là đường bình phương tối thiểu (<em>least square line</em>).</p>
<p>Đường hồi quy tổng thể là quy nhất, trong khi đường least squares thì lại có rất nhiều do được tính toán từ mẫu. Mẫu khác nhau sẽ có những đường least squares khác nhau. Trong hình dưới đây, đường màu đỏ là đường hồi quy tổng thể, màu xanh đậm là đường least squares ta tính được ở trên còn các đường xanh nhạt là các đường least squares ứng với các bộ dữ liệu khác.
<img alt="ls_vs_population" loading="lazy" src="https://uyennbu.github.io/img/Chapter3/3_3.png"></p>
<p>Có thể thấy luôn có sự khác nhau giữa các đường least squares và đường hồi quy tổng thể. Tuy nhiên least squares là ước lượng không chệch, nghĩa là nếu ta lấy trung bình các ước lượng cho $\hat{\beta_0}$ và $\hat{\beta_1}$ trên một lượng lớn các tập dữ liệu khác nhau thì giá trị $\hat{\beta_0}, \hat{\beta_1}$ này sẽ rất gần với giá trị của $\beta_0$ và $\beta_1$. Ta có thể thấy điều này trong hình bên phải.</p>
<p>Sai số chuẩn (<em>standard error</em>) cho biết ước lượng $\hat{\beta_0}$ và $\hat{\beta_1}$ sai khác như thế nào so với giá trị thực của $\beta_0$ và $\beta_1$. Với least squares sai số chuẩn được tính theo công thức:
</p>
$$
    SE(\hat{\beta_0})^2 = \sigma^2[\frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^{n}(x_i - \bar{x})^2}], \quad SE(\hat{\beta_1})^2 = \frac{\sigma^2}{\sum_{i=1}^{n}(x_i - \bar{x})^2}
$$<p>
Trong đó $\sigma^2 = Var(\epsilon)$. Khi sử dụng công thức này ta đã giả định rằng $\epsilon$ có cùng phương sai và không tương quan với nhau. Điều này không đúng (có thể xem ở hình  trước) tuy nhiên đây vẫn là một cách xấp xỉ tốt.</p>
<p>Theo công thức này, $SE(\hat{\beta_1})$ càng nhỏ khi $x_i$ càng phân tán (dữ liệu <em>leverage</em>), để dễ hình dung ta có thể nghĩ đến việc tìm hệ số góc cho đường thẳng hồi quy khi dữ liệu tụ lại thành một đám tròn, so với khi dữ liệu tản dẹt ra.</p>
<p>Với công thức tính $SE(\hat{\beta_0})$ thì nếu $\bar{x} = 0$, $SE(\hat{\beta_1}) = \sigma^2/n = SE(\hat{\mu})$ là phương sai của ước lượng cho kì vọng của Y dựa trên trung bình mẫu. Chú ý rằng $\beta_0$ là kỳ vọng của $Y$ khi X = 0.</p>
<p>Trên thực tế, ta không biết $\sigma^2$ nhưng ta có thể ước lượng cho $\sigma$ bằng RSE (<em>residual standard error</em>, sai số chuẩn phần dư) dựa trên dữ liệu theo công thức $RSE = \sqrt{RSS/(n-2)}$.</p>
<p>Sai số chuẩn có thể được dùng để tính khoảng tin cậy <em>confident interval</em>. Khoảng tin cậy 95% là khoảng mà có xác suất 95% rằng giá trị thực sẽ nằm trong nó. Trong hồi quy tuyến tính, khoảng tin cậy 95% cho $\beta_1$ được xấp xỉ bởi:
</p>
$$
    \hat{\beta_1} \pm 2 \cdot SE(\hat{\beta_1}) \\
    \text{hay } [\hat{\beta_1} - 2 \cdot SE(\hat{\beta_1}), \hat{\beta_1} + 2 \cdot SE(\hat{\beta_1})] 
$$<p>
Tương tự với $\beta_0$.</p>
<p>Trong bài toán về sales và chi phí quảng cáo trên, khoảng tin cậy 95% cho $\beta_0$ và $\beta_1$ lần lượt là <code>[6.130, 7.935]</code> và <code>[0.042, 0.053]</code>. Điều này có nghĩa là nếu không có quảng cáo thì trung bình lượng sales sẽ là 6,130 đến 7,935 sản phẩm. Thêm vào đó, với mỗi 1000 đô chi thêm cho quảng cáo trên TV thì doanh số tăng 42 đến 53 đơn vị sản phẩm.</p>
<p><strong>Vấn đề 2: Kiểm định về hệ số của mô hình</strong></p>
<p>Một câu hỏi ta cần quan tâm là, liệu X có thật sự có tác động lên Y hay không? Hay liệu có thật sự có mối quan hệ nào giữa X và Y hay không. Vì nếu không thì mô hình có hệ số góc = 0, hay $Y = \beta_0 + \epsilon$, X không có ảnh hưởng gì đến Y.</p>
<p>Ta cần kiểm định giả thiết (<em>null hypothesis</em>):</p>
<ul>
<li>$H_0$: không có mối quan hệ giữa X và Y hay $\beta_1 = 0$
với đối thiết (<em>alternative hypothesis</em>):</li>
<li>$H_a$: có mỗi quan hệ nào đó giữa X và Y, hay $\beta_1 \neq 0$</li>
</ul>
<p>Ta sẽ bác bỏ $H_0$ nếu hệ số đủ xa so vơi 0. Ta kiểm tra điều này bằng cách so khoảng cách giữa $\beta_1$ và 0 với SE($\hat{\beta_1}$). Nếu sai số của ước lượng là nhỏ, thì giá trị của $\hat{\beta_1}$ dù rất nhỏ nhưng cũng đáng kể. Ngược lại, nếu sai số ước lượng là lớn thì $\hat{\beta_1}$ cũng phải lớn tương ứng.</p>
<p>Ta sử dụng test thống kê T, giúp đo xem $\hat{\beta_1}$ cách 0 bao nhiêu độ lệch chuẩn.:
</p>
$$
    t = \frac{\hat{\beta_1} - 0}{SE(\hat{\beta_1})}
$$<p>
Nếu $H_0$ đúng, nghĩa là không có mối quan hệ giữa X và Y thì đại lượng t tuân theo phân phối t-student với $n-2$ bậc tự do, phân phối này xâp xỉ phân phối chuẩn tắc nếu n &gt; 30.</p>
<p>Đại lượng p-value là xác suất để thu được giá trị t như ta đã tính được ở trên nếu $H_0$ đúng. Nghĩa là, để kiểm định xem $H_0$ có đúng không, ta giả sử rằng nó đúng, khi đó ta sẽ xấp xỉ được phân phối của t và từ đó tính xác suất nhận được giá trị t như ta đã tính. Nếu xác suất này đủ nhỏ, ta sẽ bác bỏ $H_0$ và ngược lại.</p>
<p>Vậy ta sẽ bác bỏ $H_0$, hay ta nói rằng X và Y có mối quan hệ nào đó nếu p-value đủ nhỏ (thường là nhỏ hơn 0.05, ứng với độ tin cậy 95%).</p>
<h3 id="313-đánh-giá-độ-chính-xác-của-mô-hình">3.1.3. Đánh giá độ chính xác của mô hình<a hidden class="anchor" aria-hidden="true" href="#313-đánh-giá-độ-chính-xác-của-mô-hình">#</a></h3>
<p>Sau khi đã bác bỏ $H_0$, điều tiếp theo ta muốn làm đó là đánh giá múc độ phù hợp với dữ liệu của mô hình. Ta có một số hệ số để đánh giá như sau:</p>
<p><strong>Residual Standard Error</strong></p>
<p>Kể cả khi ta biết được đường hồi quy thật sự thì dự đoán của mô hình vẫn luôn có sai số $\epsilon$ do nhiều tác động khác bên ngoài.</p>
<p>RSE là ước lượng cho sai số chuẩn của $\epsilon$, hay nó là lượng chênh lệch trung bình của Y so với đường hồi quy thực sự (<em>true regression line</em>):
</p>
$$
    RSE = \sqrt{\frac{1}{n - 2}RSS} = \sqrt{\frac{1}{n-2}\sum_{i=1}^{n}(y_i - \hat{y_i})^2}
$$<p>RSE còn có thể coi như đại lượng đo lường độ thiếu phù hợp của mô hình <em>lack of fit</em> so với dữ liệu.</p>
<p>Thông thường, RSE càng lớn tức là mô hình không thật sự phù hợp tốt với dữ liệu.</p>
<p><strong>$R^2$ statistic</strong></p>
<p>RSE cho đo lường độ lệch tuyệt đối do đó độ lớn của nó còn phụ thuộc vào đơn vị của Y, làm việc so sánh giữa các mô hình gặp khó khăn hơn.</p>
<p>$R^2$ là một cách khác để đo độ phù hợp, do được tính theo tỉ lệ nên nó không phụ thuộc vào đơn vị của Y và luôn có giá trị trong khoảng (0,1), được xác định bởi:
</p>
$$
    R^2 = \frac{TSS - RSS}{TSS} = 1 - \frac{RSS}{TSS}
$$<p>
Trong đó TSS = $\sum_{i=1}^{n}(y_i - \bar{y})^2$ là tổng bình phương trung bình <em>total sum of squares</em>, đo lường tổng phương sai của phản hồi Y, hay sự biến động của Y trước khi sử dụng hồi quy. Ngược lại, RSS đo lường độ biến động mà không giải thích được sau khi áp dụng hồi quy.</p>
<p>Do đó, $R^2$ đo lường tỉ lệ độ biến động <em>variability</em> trong Y mà có thể giải thích được bằng X.</p>
<p>$R^2$ gần với 1 nghĩa là có một tỉ lệ lớn của sự biến động được giải thích bởi hồi quy. Còn $R^2$ gần với 0 nghĩa là hồi quy không thể giải thích được nhiều sự biến động trong phản hồi Y, điều này có thể do mô hình tuyến tính là sai hoặc phương sai của sai số $\sigma^2$ là cao, hoặc cả hai.</p>
<p><em>$R^2$ vs correlation</em></p>
<p>Hệ số tương quan <em>correlation</em>: r = Cor(X,Y) cũng giúp đo lường mối quan hệ tuyến tính giữa X và Y, được tính bởi:
</p>
$$
    Cor(X,Y) = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i-\bar{x})^2}\sqrt{\sum_{i=1}^{n}(y_i-\bar{y})^2}}
$$<p>
Trong hồi quy tuyến tính đơn ta có thể dùng r thay cho $R^2$, và ta cũng chứng minh được rằng $R^2 = r^2$. Tuy nhiên với hồi quy tuyến tính đa biến, ta không dùng r mà dùng $R^2$ do r chỉ dựa trên cặp 2 biến chứ không phải giữa một lượng lớn các biến.</p>
<hr>
<p>Bài viết được viết theo ý hiểu của mình nên có thể còn nhiều thiếu sót, mình rất vui nếu được nhận góp ý từ bạn đọc để bài viết hoàn thiện và trở nên tốt hơn. Chúc bạn một ngày tốt lành ☘️</p>
<p>Email của mình : <a href="mailto:uyennguyen.nbu@gmail.com">uyennguyen.nbu@gmail.com</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://uyennbu.github.io/tags/statistics/">Statistics</a></li>
      <li><a href="https://uyennbu.github.io/tags/machine-learning/">Machine Learning</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="https://uyennbu.github.io/book/islp/ch2_2/">
    <span class="title">Next »</span>
    <br>
    <span>Chapter 2: Introduction to Statistical Learning (2)</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn on x"
            href="https://x.com/intent/tweet/?text=Chapter%203%3a%20Linear%20Regression.%20%281%29%3a%20H%e1%bb%93i%20quy%20tuy%e1%ba%bfn%20t%c3%adnh%20%c4%91%c6%a1n&amp;url=https%3a%2f%2fuyennbu.github.io%2fbook%2fislp%2fch3_1%2f&amp;hashtags=statistics%2cmachinelearning">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fuyennbu.github.io%2fbook%2fislp%2fch3_1%2f&amp;title=Chapter%203%3a%20Linear%20Regression.%20%281%29%3a%20H%e1%bb%93i%20quy%20tuy%e1%ba%bfn%20t%c3%adnh%20%c4%91%c6%a1n&amp;summary=Chapter%203%3a%20Linear%20Regression.%20%281%29%3a%20H%e1%bb%93i%20quy%20tuy%e1%ba%bfn%20t%c3%adnh%20%c4%91%c6%a1n&amp;source=https%3a%2f%2fuyennbu.github.io%2fbook%2fislp%2fch3_1%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fuyennbu.github.io%2fbook%2fislp%2fch3_1%2f&title=Chapter%203%3a%20Linear%20Regression.%20%281%29%3a%20H%e1%bb%93i%20quy%20tuy%e1%ba%bfn%20t%c3%adnh%20%c4%91%c6%a1n">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fuyennbu.github.io%2fbook%2fislp%2fch3_1%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn on whatsapp"
            href="https://api.whatsapp.com/send?text=Chapter%203%3a%20Linear%20Regression.%20%281%29%3a%20H%e1%bb%93i%20quy%20tuy%e1%ba%bfn%20t%c3%adnh%20%c4%91%c6%a1n%20-%20https%3a%2f%2fuyennbu.github.io%2fbook%2fislp%2fch3_1%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn on telegram"
            href="https://telegram.me/share/url?text=Chapter%203%3a%20Linear%20Regression.%20%281%29%3a%20H%e1%bb%93i%20quy%20tuy%e1%ba%bfn%20t%c3%adnh%20%c4%91%c6%a1n&amp;url=https%3a%2f%2fuyennbu.github.io%2fbook%2fislp%2fch3_1%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Chapter 3: Linear Regression. (1): Hồi quy tuyến tính đơn on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Chapter%203%3a%20Linear%20Regression.%20%281%29%3a%20H%e1%bb%93i%20quy%20tuy%e1%ba%bfn%20t%c3%adnh%20%c4%91%c6%a1n&u=https%3a%2f%2fuyennbu.github.io%2fbook%2fislp%2fch3_1%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2026 <a href="https://uyennbu.github.io/">Uyen&#39;s blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
