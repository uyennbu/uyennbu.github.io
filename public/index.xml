<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Uyen&#39;s blog</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Uyen&#39;s blog</description>
    <generator>Hugo -- 0.152.2</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Jan 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Nh·ªØng l·ªùi ƒë·∫ßu ti√™n</title>
      <link>http://localhost:1313/myjourney/first_lines/</link>
      <pubDate>Fri, 09 Jan 2026 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/myjourney/first_lines/</guid>
      <description>&lt;p&gt;B√†i vi·∫øt n√†y thu·ªôc series &amp;ldquo;Study in HUS&amp;rdquo;, n∆°i m√¨nh chia s·∫ª nh·ªØng c·∫£m nh·∫≠n v√† suy nghƒ© c·ªßa m√¨nh trong qu√° tr√¨nh h·ªçc t·∫≠p l·∫°i HUS.&lt;/p&gt;
&lt;h1 id=&#34;nh√¨n-l·∫°i&#34;&gt;Nh√¨n l·∫°i&lt;/h1&gt;
&lt;p&gt;H√¥m nay l√† 9/1/2026, m√¨nh ch∆∞a thi xong h·∫øt h·ªçc k√¨ 1 nh∆∞ng c≈©ng c√≤n 1 m√¥n n·ªØa th√¥i, c≈©ng coi nh∆∞ ƒë√£ ho√†n th√†nh h·ªçc k√¨ n√†y r·ªìi. V·∫≠y l√† m√¨nh ƒë√£ tr·∫£i qua 3 h·ªçc k√¨ t·∫°i HUS, c≈©ng m·ªõi ch·ªâ l√† 3/8 k√¨ h·ªçc, n·∫øu m√¨nh h·ªçc ƒë·ªß 8 k√¨. Nh∆∞ng m√† c√≥ th·ªÉ m√¨nh s·∫Ω kh√¥ng d√πng h·∫øt 8 k√¨ n√†y, h√¥m tr∆∞·ªõc xem l·∫°i m√¨nh th·∫•y ch·∫Øc m√¨nh ch·ªâ c·∫ßn 6 - 7 k√¨ l√† xong r·ªìi, v·∫≠y m√¨nh c≈©ng coi nh∆∞ ƒë√£ ƒëi ƒë∆∞·ª£c n·ª≠a ƒë∆∞·ªùng r·ªìi, s·∫Øp ra tr∆∞·ªùng (h∆°i s·ªõm nh∆∞ng d·∫°o n√†y m√¨nh th·∫≠t s·ª± c√≥ c·∫£m gi√°c ·∫•y üòÇ)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 4: Classification</title>
      <link>http://localhost:1313/book/islp/ch4_classification/</link>
      <pubDate>Tue, 25 Nov 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/book/islp/ch4_classification/</guid>
      <description>&lt;p&gt;As we all know, there are two main types of data: quantitative and qualitative. The linear regression models in previous chapters help us to predict quantitative responses. But what about qualitative ones?&lt;/p&gt;
&lt;p&gt;The task of predicting qualitative responses is known as &lt;em&gt;classification&lt;/em&gt;. In this chapter, we will walk through the base idea of classification and some of the most basic and common classification models.&lt;/p&gt;
&lt;p&gt;Some examples of classification problems include:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chapter 1: Introduction and examples</title>
      <link>http://localhost:1313/book/firstcoursebayes/ch1_intro/</link>
      <pubDate>Wed, 12 Nov 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/book/firstcoursebayes/ch1_intro/</guid>
      <description>&lt;h1 id=&#34;chapter-1-introduction-and-examples&#34;&gt;Chapter 1: Introduction and examples&lt;/h1&gt;
&lt;h2 id=&#34;what-is-bayesian-statistics&#34;&gt;What is Bayesian Statistics?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Bayesian inference is the process of &lt;strong&gt;inductive&lt;/strong&gt; learning via Bayes&amp;rsquo; rule.&lt;/li&gt;
&lt;li&gt;Bayes rule does not tell us what our beliefs should be, it tells us how should they change after seeing new information.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;notation&#34;&gt;Notation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;parameters: $\theta$ (we call it parameter because we calculate y from it, in normal cases)&lt;/li&gt;
&lt;li&gt;dataset: $y$ (sample of the population)&lt;/li&gt;
&lt;li&gt;sample space : $\mathcal{Y}$ (all possible datasets)&lt;/li&gt;
&lt;li&gt;parameter space : $\Theta$ (all possible parameters)&lt;/li&gt;
&lt;li&gt;prior distribution: $p(\theta)$ (for each $\theta \in \Theta$, $p(\theta)$ is our belief that $\theta$ represents the true population chracteristic)&lt;/li&gt;
&lt;li&gt;sampling method: $p(y|\theta)$ (our belief that $y$ should be observed if $\theta$ is known)&lt;/li&gt;
&lt;li&gt;posterior distribution: $p(\theta|y)$ (our belief that $\theta$ is the true population characteristic after observing $y$)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bayes-rule&#34;&gt;Bayes&amp;rsquo; Rule&lt;/h2&gt;
$$p(\theta|y) = \frac{p(y|\theta)p(\theta)}{\int_\Theta p(y|\tilde{\theta})p(\tilde{\theta})d\tilde{\theta}}$$&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;
&lt;h3 id=&#34;using-bayes-inference-to-estimate-posterior-probability&#34;&gt;Using Bayes inference to estimate posterior probability&lt;/h3&gt;
&lt;h3 id=&#34;using-bayes-inference-to-estimate-parameter-in-a-predictive-model&#34;&gt;Using Bayes inference to estimate parameter in a predictive model&lt;/h3&gt;</description>
    </item>
    <item>
      <title>Chapter 2: Belief, Probbility, and Exchangeability</title>
      <link>http://localhost:1313/book/firstcoursebayes/ch2_belief_prob_exchangeability/</link>
      <pubDate>Wed, 12 Nov 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/book/firstcoursebayes/ch2_belief_prob_exchangeability/</guid>
      <description>&lt;h2 id=&#34;belief-function-and-probability&#34;&gt;Belief function and Probability&lt;/h2&gt;
&lt;h2 id=&#34;events-partitions-and-bayes-rule&#34;&gt;Events, partitions, and Bayes&amp;rsquo; rule&lt;/h2&gt;
&lt;h2 id=&#34;independence&#34;&gt;Independence&lt;/h2&gt;
&lt;h2 id=&#34;random-variables&#34;&gt;Random variables&lt;/h2&gt;
&lt;h3 id=&#34;discrete-random-variables&#34;&gt;Discrete random variables&lt;/h3&gt;
&lt;h3 id=&#34;continuous-random-variables&#34;&gt;Continuous random variables&lt;/h3&gt;
&lt;h2 id=&#34;joint-distributions&#34;&gt;Joint distributions&lt;/h2&gt;
&lt;h2 id=&#34;independent-random-variables&#34;&gt;Independent random variables&lt;/h2&gt;
&lt;h2 id=&#34;exchangeability&#34;&gt;Exchangeability&lt;/h2&gt;
&lt;h3 id=&#34;de-finettis-theorem&#34;&gt;De Finetti&amp;rsquo;s theorem&lt;/h3&gt;</description>
    </item>
    <item>
      <title>Chapter 2: Introduction to Statistical Learning</title>
      <link>http://localhost:1313/book/islp/ch2_statistical_learning/</link>
      <pubDate>Wed, 12 Nov 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/book/islp/ch2_statistical_learning/</guid>
      <description>&lt;h2 id=&#34;what-is-statistical-learning&#34;&gt;What is Statistical Learning?&lt;/h2&gt;</description>
    </item>
    <item>
      <title>Chapter 3: One-parameter models</title>
      <link>http://localhost:1313/book/firstcoursebayes/ch3_one_prarameter_models/</link>
      <pubDate>Wed, 12 Nov 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/book/firstcoursebayes/ch3_one_prarameter_models/</guid>
      <description>&lt;h2 id=&#34;binomial-model&#34;&gt;Binomial model&lt;/h2&gt;
&lt;h2 id=&#34;poisson-model&#34;&gt;Poisson model&lt;/h2&gt;
&lt;h2 id=&#34;exponential-model&#34;&gt;Exponential model&lt;/h2&gt;</description>
    </item>
    <item>
      <title>Second</title>
      <link>http://localhost:1313/demo/second/</link>
      <pubDate>Mon, 15 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/demo/second/</guid>
      <description>&lt;h1 id=&#34;second-demo&#34;&gt;Second Demo&lt;/h1&gt;
&lt;p&gt;This is the content of the second demo post.&lt;/p&gt;</description>
    </item>
    <item>
      <title>First Demo</title>
      <link>http://localhost:1313/demo/first/</link>
      <pubDate>Sat, 15 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/demo/first/</guid>
      <description>&lt;h1 id=&#34;first-demo&#34;&gt;First Demo&lt;/h1&gt;
&lt;p&gt;This is the content of the first demo post.&lt;/p&gt;</description>
    </item>
    <item>
      <title>About Me</title>
      <link>http://localhost:1313/about/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/about/</guid>
      <description>&lt;h1 id=&#34;about-me&#34;&gt;About Me&lt;/h1&gt;
&lt;p&gt;M√¨nh t√™n l√† Nguy·ªÖn B√≠ch Uy√™n, ƒëang l√† sinh vi√™n ng√†nh khoa h·ªçc d·ªØ li·ªáu t·∫°i tr∆∞·ªùng ƒê·∫°i h·ªçc Khoa h·ªçc T·ª± nhi√™n, ƒê·∫°i h·ªçc Qu·ªëc gia H√† N·ªôi. M√¨nh vi·∫øt blog n√†y ƒë·ªÉ chia s·∫ª nh·ªØng ki·∫øn th·ª©c m√¨nh h·ªçc ƒë∆∞·ª£c v·ªÅ th·ªëng k√™ v√† h·ªçc m√°y, c≈©ng nh∆∞ nh·ªØng tr·∫£i nghi·ªám c·ªßa m√¨nh trong qu√° tr√¨nh h·ªçc t·∫≠p t·∫°i HUS.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
